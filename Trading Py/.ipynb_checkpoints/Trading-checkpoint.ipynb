{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2225f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Author: Sukhwinder Ahluwalia\n",
    "# Purpose: Data download + analysis\n",
    "# Date: 3rd September 2020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0d4e5d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Installing necessary packages\n",
    "# !pip install pyautogui\n",
    "# !pip install time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d7d6d263",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Download other Forex and Metals tickers\n",
    "Curr = [\n",
    "    #Currencies\n",
    "#     \"AUDCAD\", \"AUDCHF\",\n",
    "#     \"AUDJPY\", \"AUDNZD\", \"AUDSGD\", \n",
    "#     \"CADCHF\", \"CADJPY\", \"CHFJPY\", \"CHFSGD\",\n",
    "#     \"EURAUD\", \"EURCAD\", \"EURCHF\", \"EURCZK\", \"EURGBP\", \"EURHUF\", \"EURJPY\",\n",
    "#     \"EURMXN\", \"EURNOK\", \"EURNZD\", \"EURPLN\", \"EURSEK\", \"EURSGD\", \"EURTRY\", \"EURZAR\",\n",
    "#     \"GBPAUD\", \"GBPCAD\", \"GBPCHF\", \"GBPJPY\", \"GBPMXN\", \"GBPNOK\", \"GBPNZD\", \"GBPSEK\", \"GBPSGD\", \"GBPTRY\", \n",
    "#     \"NOKJPY\", \"NOKSEK\", \"NZDCAD\", \"NZDCHF\", \"NZDJPY\", \"SEKJPY\", \"SGDJPY\",\n",
    "    \"USDCAD\", \"USDCHF\", \"USDCNH\", \"USDCZK\", \"USDHUF\", \"USDJPY\", \"USDMXN\", \"USDNOK\", \"USDPLN\", \"USDSEK\",\n",
    "    \"USDSGD\", \"USDTHB\", \"USDTRY\", \"USDZAR\", \"USDIDR\", \"USDINR\", \n",
    "    'USDX.a','EURX',\n",
    "    \"EURUSD\", \"GBPUSD\",\"NZDUSD\", \"AUDUSD\", \n",
    "    \n",
    "#     #Metals\n",
    "#     \"XAGAUD\", \"XAGEUR\",  \"XAUAUD\", \"XAUCHF\", \"XAUEUR\",\n",
    "#     \"XAUGBP\", \"XAUJPY\", \n",
    "    \"XAGUSD.a\",\"XAUUSD.a\", \"XPTUSD.a\",\n",
    "    \n",
    "#     #ETFs\n",
    "    'AUS200.a','US30.a','US500.a','UK100.a','NAS100.a','EUSTX50.a','SPA35.a','JPN225.a', 'GER40.a','HK50.a',\n",
    "    \n",
    "#     # US Shares tickers\n",
    "    \"AMD.US-24\", \"BABA.US-24\", \"GOOG.US-24\", \"AMZN.US-24\", \"AAPL.US-24\", \"BAC.US-24\", \"CAT.US-24\",\n",
    "    \"CVX.US-24\", \"C.US-24\", \"XOM.US-24\", \"F.US-24\", \"GM.US-24\", \"HPQ.US-24\", \"IBM.US-24\", \"INTC.US-24\",\n",
    "    \"JPM.US-24\", \"JNJ.US-24\", \"MCD.US-24\", \"META.US-24\", \"MSFT.US-24\", \"NKE.US-24\", \"NVDA.US-24\",\n",
    "    \"NFLX.US-24\", \"ORCL.US-24\", \"PFE.US-24\", \"PG.US-24\", \"SLB.US-24\", \"SNAP.US-24\", \"TSLA.US-24\",\n",
    "    \"BA.US-24\", \"KO.US-24\", \"DIS.US-24\", \"UNH.US-24\", \"VZ.US-24\", \"RTX.US-24\", \"V.US-24\", \"WMT.US-24\"\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d1ef235f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! python3\n",
    "# mouseNow.py - Displays the mouse cursor's current position.\n",
    "import pyautogui\n",
    "import time\n",
    "#Mouse coordinates. = x = (0,1919) y = (0,1079)\n",
    "\n",
    "pyautogui.PAUSE = 4\n",
    "\n",
    "#Get to Pepperstone app\n",
    "pyautogui.click(25, 900)\n",
    "# pyautogui.PAUSE = 1\n",
    "pyautogui.click(350, 200)\n",
    "#pyautogui.hotkey('alt', 'tab')\n",
    "pyautogui.PAUSE = 2\n",
    "\n",
    "#Get to currency page\n",
    "pyautogui.hotkey('ctrl', 'u')\n",
    "\n",
    "#Get to Bars\n",
    "pyautogui.click(500, 235)\n",
    "#Download AUDUSD\n",
    "pyautogui.typewrite(\"audusd\")\n",
    "pyautogui.hotkey('enter')\n",
    "pyautogui.hotkey('tab')\n",
    "pyautogui.typewrite('d') #Daily\n",
    "pyautogui.click(1000, 265) #Request\n",
    "pyautogui.click(480, 640) #Export\n",
    "#time.sleep(2)\n",
    "pyautogui.click(700, 215) #Change the directory for these\n",
    "pyautogui.typewrite(\"C:\\\\Users\\\\nitis\\\\Documents\\\\Forex\\\\Data\\\\New data\") #Use directory\n",
    "pyautogui.hotkey('enter')\n",
    "pyautogui.click(700, 550) #Change the name\n",
    "pyautogui.typewrite('audusd') #Save file as aud\n",
    "pyautogui.hotkey('enter')\n",
    "pyautogui.typewrite('y')\n",
    "\n",
    "#Loop through all currencies, len(daily)\n",
    "for i in range(0,len(Curr)):\n",
    "    pyautogui.click(490, 265) #Currency type\n",
    "    pyautogui.typewrite(Curr[i])\n",
    "    pyautogui.hotkey('enter')\n",
    "    pyautogui.click(1000, 265) #Request\n",
    "    pyautogui.click(1000, 265) #Request again\n",
    "    pyautogui.click(480, 640) #Export\n",
    "#    time.sleep(2)\n",
    "    pyautogui.typewrite(Curr[i]) #Save file \n",
    "    pyautogui.hotkey('enter')\n",
    "    pyautogui.typewrite('y')\n",
    "\n",
    "#Exit currency page\n",
    "pyautogui.hotkey('esc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "6ed27d7f",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'C:\\\\Users\\\\nitis\\\\Documents\\\\Forex\\\\Data\\\\New data\\\\USDCAD'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[41], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;28mlen\u001b[39m(Curr)):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m#Load new data\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mfr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCurr[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 10\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(path, sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m#Load hist data\u001b[39;00m\n\u001b[0;32m     12\u001b[0m     path_hist \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mfr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbase_path_hist\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCurr[i]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    209\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[38;5;241m=\u001b[39m new_arg_value\n\u001b[1;32m--> 211\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    330\u001b[0m     )\n\u001b[1;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[0;32m    935\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m    936\u001b[0m     dialect,\n\u001b[0;32m    937\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    946\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[0;32m    947\u001b[0m )\n\u001b[0;32m    948\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m--> 950\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    602\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    604\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 605\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    607\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    608\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1439\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1441\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1442\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1733\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1734\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1735\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1736\u001b[0m     f,\n\u001b[0;32m   1737\u001b[0m     mode,\n\u001b[0;32m   1738\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1739\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1740\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1741\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1742\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1743\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1744\u001b[0m )\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    851\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    852\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    853\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    854\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    855\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 856\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    857\u001b[0m             handle,\n\u001b[0;32m    858\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    859\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    860\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    861\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    862\u001b[0m         )\n\u001b[0;32m    863\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    864\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    865\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'C:\\\\Users\\\\nitis\\\\Documents\\\\Forex\\\\Data\\\\New data\\\\USDCAD'"
     ]
    }
   ],
   "source": [
    "#Join on to historical datasets: FIX THE .a THING!!!!\n",
    "# Analysis on the datasets\n",
    "base_path = r\"C:\\Users\\nitis\\Documents\\Forex\\Data\\New data\"\n",
    "base_path_hist = r\"C:\\Users\\nitis\\Documents\\Forex\\Data\\New data\\Hist data\"\n",
    "\n",
    "#Loop through all currencies, len(daily)\n",
    "for i in range(0,len(Curr)):\n",
    "    #Load new data\n",
    "    path = fr\"{base_path}\\{Curr[i]}.csv\"\n",
    "    df = pd.read_csv(path, sep='\\t')\n",
    "    #Load hist data\n",
    "    path_hist = fr\"{base_path_hist}\\{Curr[i]}.csv\"\n",
    "    df_hist = pd.read_csv(path_hist, sep='\\t')\n",
    "    #Save total data in hist\n",
    "    combined = pd.concat([df_hist, df], ignore_index=True)\n",
    "    combined = combined.drop_duplicates()\n",
    "    combined.to_csv(path_hist, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac81f49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#To do:\n",
    "# 3. Also check for recent surprise jumps perhaps - a glut or a squeeze which may see a reaction soon etc\n",
    "\n",
    "# 0. Load above datasets other than aud using function and datasets etc\n",
    "# 1. Rates for non USD stuff and create more datasets and opps - applies to currency + metals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68ab67e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data and basic analyses\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "from datetime import date\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#Get slope for the MAs\n",
    "def numpy_slope(series, window=10):\n",
    "    def calc_slope(x):\n",
    "        if len(x) < window:\n",
    "            return np.nan\n",
    "        coeffs = np.polyfit(range(len(x)), x, 1)\n",
    "        return coeffs[0]\n",
    "    \n",
    "    return series.rolling(window=window).apply(calc_slope)\n",
    "\n",
    "#Run function\n",
    "def Run(df,name):\n",
    "    #Currency and dates\n",
    "    df['Currency'] = name\n",
    "    df['<DATE>'] = pd.to_datetime(df['<DATE>'], format='%Y.%m.%d')\n",
    "    df.set_index('<DATE>')\n",
    "    # Note these below apply to Lows and Highs\n",
    "    df['1m_MA_Filter'] = 0 \n",
    "    df['3m_MA_Filter'] = 0\n",
    "    df['6m_MA_Filter'] = 0\n",
    "    df['12m_MA_Filter'] = 0\n",
    "    df['AT_MA_Filter'] = 0\n",
    "\n",
    "    #High/Low since 1 month: 23 days or so\n",
    "    df['1m_High'] = df['<CLOSE>'].rolling(window=23).max()\n",
    "    df['1m_Low'] = df['<CLOSE>'].rolling(window=23).min()\n",
    "    df['1m_Mean'] = df['<CLOSE>'].rolling(23).mean()\n",
    "        \n",
    "    #High/Low since 3 months: 70 days or so\n",
    "    df['3m_High'] = df['<CLOSE>'].rolling(window=70).max()\n",
    "    df['3m_Low'] = df['<CLOSE>'].rolling(window=70).min()\n",
    "    df['3m_Mean'] = df['<CLOSE>'].rolling(70).mean()\n",
    "    \n",
    "    #High/Low since 6 months: 135 days or so\n",
    "    df['6m_High'] = df['<CLOSE>'].rolling(window=135).max()\n",
    "    df['6m_Low'] = df['<CLOSE>'].rolling(window=135).min()\n",
    "    df['6m_Mean'] = df['<CLOSE>'].rolling(135).mean()\n",
    "    \n",
    "    #High/Low since 12 months: 260 days or so\n",
    "    df['12m_High'] = df['<CLOSE>'].rolling(window=260).max()\n",
    "    df['12m_Low'] = df['<CLOSE>'].rolling(window=260).min()\n",
    "    df['12m_Mean'] = df['<CLOSE>'].rolling(260).mean()\n",
    "        \n",
    "    #High/Low since 2022\n",
    "    df['AT_High'] = df['<CLOSE>'].max()\n",
    "    df['AT_Low'] = df['<CLOSE>'].min()\n",
    "    df['AT_Mean'] = df['<CLOSE>'].mean()\n",
    "    df['AT_Med'] = df['<CLOSE>'].median()\n",
    "    \n",
    "    # List of time periods\n",
    "    time_periods = ['1m', '3m', '6m', '12m', 'AT']\n",
    "\n",
    "    # Create 90th percentile slope filters for each time period\n",
    "    for period in time_periods:\n",
    "        # Create MA Filter for High and Close\n",
    "        df.loc[round(df[f'{period}_High'], 2) == round(df['<CLOSE>'], 2), f'{period}_MA_Filter'] = 1\n",
    "\n",
    "        # Create MA Filter for Low and Close\n",
    "        df.loc[round(df[f'{period}_Low'], 2) == round(df['<CLOSE>'], 2), f'{period}_MA_Filter'] = 1\n",
    "\n",
    "        # Calculate Slope\n",
    "        df[f'{period}_MA_slope'] = numpy_slope(df[f'{period}_Mean'])\n",
    "\n",
    "        # Normalize Slope\n",
    "        df[f'{period}_MA_slope_nm'] = (df[f'{period}_MA_slope'] - df[f'{period}_MA_slope'].mean()) / df[f'{period}_MA_slope'].std()\n",
    "       \n",
    "        # Create binary filter column on the percentile\n",
    "        df[f'{period}_slope'] = (df[f'{period}_MA_slope_nm'] >= df[f'{period}_MA_slope_nm'].quantile(0.9)).astype(int)\n",
    "    \n",
    "    # MA Crosses: Where rounded till 3 is the same eg 0.6659 = 0.6663 = 0.666 etc\n",
    "    # 1m vs 3m\n",
    "    df.loc[round(df['1m_Mean'], 3) == round(df['3m_Mean'], 3), 'MA_1_3'] = 1\n",
    "\n",
    "    # 1m vs 6m\n",
    "    df.loc[round(df['1m_Mean'], 3) == round(df['6m_Mean'], 3), 'MA_1_6'] = 1\n",
    "\n",
    "    # 1m vs 12m\n",
    "    df.loc[round(df['1m_Mean'], 3) == round(df['12m_Mean'], 3), 'MA_1_12'] = 1\n",
    "\n",
    "    # 1m vs AT\n",
    "    df.loc[round(df['1m_Mean'], 3) == round(df['AT_Mean'], 3), 'MA_1_AT'] = 1\n",
    "\n",
    "    # 3m vs 6m\n",
    "    df.loc[round(df['3m_Mean'], 3) == round(df['6m_Mean'], 3), 'MA_3_6'] = 1\n",
    "\n",
    "    # 3m vs 12m\n",
    "    df.loc[round(df['3m_Mean'], 3) == round(df['12m_Mean'], 3), 'MA_3_12'] = 1\n",
    "\n",
    "    # 3m vs AT\n",
    "    df.loc[round(df['3m_Mean'], 3) == round(df['AT_Mean'], 3), 'MA_3_AT'] = 1\n",
    "\n",
    "    # 6m vs 12m\n",
    "    df.loc[round(df['6m_Mean'], 3) == round(df['12m_Mean'], 3), 'MA_6_12'] = 1\n",
    "\n",
    "    # 6m vs AT\n",
    "    df.loc[round(df['6m_Mean'], 3) == round(df['AT_Mean'], 3), 'MA_6_AT'] = 1\n",
    "\n",
    "    # 12m vs AT\n",
    "    df.loc[round(df['12m_Mean'], 3) == round(df['AT_Mean'], 3), 'MA_12_AT'] = 1\n",
    "\n",
    "    # Optional: Fill NaN with 0 if needed\n",
    "    ma_filter_columns = [\n",
    "        'MA_1_3', 'MA_1_6', 'MA_1_12', 'MA_1_AT', \n",
    "        'MA_3_6', 'MA_3_12', 'MA_3_AT', \n",
    "        'MA_6_12', 'MA_6_AT', \n",
    "        'MA_12_AT'\n",
    "    ]\n",
    "    \n",
    "    for col in ma_filter_columns:\n",
    "        df[col] = df[col].fillna(0)\n",
    "        \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "653661fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trends. Where opps lie:\n",
    "def Filter(df_c, filter_columns):\n",
    "    # Create the filter condition\n",
    "    filter_condition = ' | '.join([f'(df_c[\"{col}\"]==1)' for col in filter_columns])\n",
    "    \n",
    "    # Create cumulative filter column\n",
    "    df_c2 = df_c.copy()\n",
    "    df_c2['Total_Filters'] = df_c2[filter_columns].sum(axis=1)\n",
    "    \n",
    "    # Apply the filter\n",
    "    return df_c2[eval(filter_condition)]\n",
    "\n",
    "# To do\n",
    "# # - For stocks, open/close gap analyses\n",
    "# - Close is near AT median then it may touch it soon? - Weak    \n",
    "\n",
    "# MA crosses and slopes not used RN\n",
    "# 'MA_3_12', 'MA_3_AT', \n",
    "#         'MA_6_12', \n",
    "# ,'12m_slope','AT_slope'\n",
    "\n",
    "# #Additional filters: Volumes analysis\n",
    "# Enhancement\tDescription\tImplementation Strategy\n",
    "# Volume Validation\tIncorporate trading volume as a critical confirmation signal\t- Add volume threshold criteria for each trigger (e.g., > 1.5x average daily volume)\n",
    "# Volume Divergence\tIdentify discrepancies between price movement and volume\t- Compare current volume to historical volume patterns\n",
    "# Volume Profile\tAnalyze volume distribution at key price levels\t- Highlight high-volume nodes as potential support/resistance zones\n",
    "\n",
    "#Checks\n",
    "# df_wk['12m_MA_Filter'].value_counts()\n",
    "# df_st['12m_MA_Filter'].value_counts()\n",
    "# df_wk.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "83eb7283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       <DATE>    Currency  Total_Filters\n",
      "0  2025-09-05   AMD.US-24            1.0\n",
      "1  2025-09-02  BABA.US-24            1.0\n",
      "2  2025-09-05  GOOG.US-24            1.0\n",
      "3  2025-09-04  AMZN.US-24            1.0\n",
      "4  2025-09-04  AAPL.US-24            1.0\n",
      "5  2025-09-05  AAPL.US-24            1.0\n",
      "6  2025-08-29   BAC.US-24            1.0\n",
      "7  2025-09-02   CVX.US-24            1.0\n",
      "8  2025-09-04     C.US-24            1.0\n",
      "9  2025-09-02   XOM.US-24            1.0\n",
      "10 2025-09-05   HPQ.US-24            1.0\n",
      "11 2025-09-05   IBM.US-24            1.0\n",
      "12 2025-09-05   JPM.US-24            1.0\n",
      "13 2025-09-04   MCD.US-24            1.0\n",
      "14 2025-09-02  META.US-24            1.0\n",
      "15 2025-09-05  MSFT.US-24            1.0\n",
      "16 2025-09-05   NKE.US-24            1.0\n",
      "17 2025-09-05  NVDA.US-24            1.0\n",
      "18 2025-09-04  NFLX.US-24            1.0\n",
      "19 2025-09-03  ORCL.US-24            1.0\n",
      "20 2025-09-04   PFE.US-24            1.0\n",
      "21 2025-09-05    PG.US-24            1.0\n",
      "22 2025-08-29   SLB.US-24            1.0\n",
      "23 2025-09-02  SNAP.US-24            1.0\n",
      "24 2025-09-02    BA.US-24            1.0\n",
      "25 2025-09-05    KO.US-24            1.0\n",
      "26 2025-09-05   UNH.US-24            1.0\n",
      "27 2025-08-29   RTX.US-24            1.0\n",
      "28 2025-08-29     V.US-24            1.0\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "# Analysis on the datasets\n",
    "base_path_hist = r\"C:\\Users\\nitis\\Documents\\Forex\\Data\\New data\\Hist data\"\n",
    "#  store non-empty dfs\n",
    "collected_st = []\n",
    "collected_wk = []\n",
    "\n",
    "#Loop through all currencies, len(daily)\n",
    "for i in range(0,len(Curr)):\n",
    "    path = fr\"{base_path}\\{Curr[i]}.csv\"\n",
    "    df = pd.read_csv(path, sep='\\t')\n",
    "    df2 = Run(df,Curr[i])\n",
    "    df2 = df2.tail()\n",
    "\n",
    "    # Strong set: 4 filters\n",
    "    # - Close is near AT and/or 12m H/L then time could be to reverse - Strong\n",
    "    # - Rolling MA crosses comparisons for 12 with various and AT\n",
    "    df_st = Filter(df2, ['AT_MA_Filter', '12m_MA_Filter'\n",
    "                        ,'MA_6_AT','MA_12_AT'])\n",
    "    \n",
    "    df_st = df_st [['<DATE>', 'Currency', 'Total_Filters']]\n",
    "    df_st = df_st.drop_duplicates()\n",
    "    \n",
    "    # Weak set: 11 filters\n",
    "    # - Close is near other H/L then time could be to reverse - Weak\n",
    "    # - Rolling MA crosses comparisons for 1 with various and 3/6\n",
    "    # - Slopes for sudden jumps\n",
    "    df_wk = Filter(df2, ['1m_MA_Filter','3m_MA_Filter','6m_MA_Filter'\n",
    "                         ,'MA_1_3', 'MA_1_6', 'MA_1_12', 'MA_1_AT','MA_3_6'\n",
    "                        ,'1m_slope','3m_slope','6m_slope'])\n",
    "    \n",
    "    df_wk = df_wk [['<DATE>', 'Currency', 'Total_Filters']]   \n",
    "    df_wk = df_wk.drop_duplicates()\n",
    "\n",
    "    #Collect data in one set\n",
    "    if not df_st.empty:\n",
    "        collected_st.append(df_st)\n",
    "\n",
    "    if not df_wk.empty:\n",
    "        collected_wk.append(df_wk)\n",
    "\n",
    "if collected_st:\n",
    "    result_st = pd.concat( collected_st, ignore_index=True)\n",
    "else:\n",
    "    result_st = pd.DataFrame()  # empty result\n",
    "\n",
    "if collected_wk:\n",
    "    result_wk = pd.concat(collected_wk, ignore_index=True)\n",
    "else:\n",
    "    result_wk = pd.DataFrame()  # empty result\n",
    "\n",
    "print(result_st)\n",
    "print(result_wk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d90d744",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "incomplete input (695976308.py, line 35)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[9], line 35\u001b[1;36m\u001b[0m\n\u001b[1;33m    df = pd.DataFrame(all_tickers, columns\u001b[0m\n\u001b[1;37m                                          ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m incomplete input\n"
     ]
    }
   ],
   "source": [
    "# Other shares, softs, hards, etc\n",
    "\n",
    "# AU Shares tickers\n",
    "au_share_tickers = [\n",
    "    \"A2M.AU\", \"ABC.AU\", \"AGL.AU\", \"AIA.AU\", \"AIZ.AU\", \"ALD.AU\", \"ALQ.AU\", \"ALU.AU\", \"ALX.AU\", \"AMC.AU\",\n",
    "    \"AMP.AU\", \"ANN.AU\", \"ANZ.AU\", \"APA.AU\", \"APE.AU\", \"APX.AU\", \"ARG.AU\", \"ARB.AU\", \"ASB.AU\", \"ASX.AU\",\n",
    "    \"AST.AU\", \"AUB.AU\", \"AWB.AU\", \"AWL.AU\", \"AWN.AU\", \"AWC.AU\", \"BEN.AU\", \"BGA.AU\", \"BHP.AU\", \"BIN.AU\",\n",
    "    \"BKL.AU\", \"BKW.AU\", \"BLD.AU\", \"BOQ.AU\", \"BPT.AU\", \"BRG.AU\", \"BSL.AU\", \"BVS.AU\", \"BWP.AU\", \"BXB.AU\",\n",
    "    \"CAR.AU\", \"CBA.AU\", \"CCP.AU\", \"CCL.AU\", \"CGC.AU\", \"CGF.AU\", \"CHC.AU\", \"CIP.AU\", \"CIM.AU\", \"CIA.AU\",\n",
    "    \"CLW.AU\", \"CMW.AU\", \"CNU.AU\", \"COL.AU\", \"COE.AU\", \"COH.AU\", \"CPU.AU\", \"CQR.AU\", \"CRN.AU\", \"CSL.AU\",\n",
    "    \"CSR.AU\", \"CTD.AU\", \"CUV.AU\", \"CWN.AU\", \"CWY.AU\", \"DHG.AU\", \"DMP.AU\", \"DOW.AU\", \"DDR.AU\", \"DEG.AU\",\n",
    "    \"DRR.AU\", \"DXS.AU\", \"EBO.AU\", \"EHE.AU\", \"EHL.AU\", \"ELD.AU\", \"EHE.AU\", \"EML.AU\", \"EVT.AU\", \"EVN.AU\",\n",
    "    \"FBU.AU\", \"FLT.AU\", \"FMG.AU\", \"FPH.AU\", \"GEM.AU\", \"GNC.AU\", \"GMG.AU\", \"GOR.AU\", \"GOZ.AU\", \"GPT.AU\",\n",
    "    \"GQG.AU\", \"GUD.AU\", \"GWA.AU\", \"HDN.AU\", \"HLS.AU\", \"HMC.AU\", \"HUB.AU\", \"HVN.AU\", \"IAG.AU\", \"IFT.AU\",\n",
    "    \"IEL.AU\", \"IFM.AU\", \"IFL.AU\", \"ILU.AU\", \"INA.AU\", \"INC.AU\", \"IRE.AU\", \"IPL.AU\", \"IPH.AU\", \"IVC.AU\",\n",
    "    \"JBH.AU\", \"JHX.AU\", \"JHG.AU\", \"JIN.AU\", \"KGN.AU\", \"LNK.AU\", \"LIS.AU\", \"LLC.AU\", \"LOV.AU\", \"LTR.AU\",\n",
    "    \"LYC.AU\", \"MFG.AU\", \"MIN.AU\", \"MGR.AU\", \"MMS.AU\", \"MPL.AU\", \"MP1.AU\", \"MQG.AU\", \"MTS.AU\", \"MYX.AU\",\n",
    "    \"NAN.AU\", \"NAB.AU\", \"NEC.AU\", \"NEU.AU\", \"NHC.AU\", \"NHF.AU\", \"NIC.AU\", \"NEM.AU\", \"NCM.AU\", \"NEA.AU\",\n",
    "    \"NUF.AU\", \"NSR.AU\", \"NWH.AU\", \"NXT.AU\", \"NWL.AU\", \"ORA.AU\", \"ORG.AU\", \"ORI.AU\", \"OML.AU\", \"ORE.AU\",\n",
    "    \"OZL.AU\", \"PDL.AU\", \"PDN.AU\", \"PER.AU\", \"PLS.AU\", \"PME.AU\", \"PMV.AU\", \"PNI.AU\", \"PNV.AU\", \"PPK.AU\",\n",
    "    \"PPT.AU\", \"PRN.AU\", \"PRU.AU\", \"PTM.AU\", \"PXA.AU\", \"QAN.AU\", \"QBE.AU\", \"QUB.AU\", \"RBL.AU\", \"REA.AU\",\n",
    "    \"REH.AU\", \"REG.AU\", \"RHC.AU\", \"RIO.AU\", \"RMD.AU\", \"RRL.AU\", \"RSG.AU\", \"RWC.AU\", \"S32.AU\", \"SAR.AU\",\n",
    "    \"SBM.AU\", \"SCA.AU\", \"SCG.AU\", \"SCP.AU\", \"SDG.AU\", \"SDF.AU\", \"SEK.AU\", \"SFR.AU\", \"SGM.AU\", \"SHL.AU\",\n",
    "    \"SIQ.AU\", \"SKC.AU\", \"SKI.AU\", \"SLC.AU\", \"SLR.AU\", \"SML.AU\", \"SMR.AU\", \"SOL.AU\", \"SPK.AU\", \"SSG.AU\",\n",
    "    \"STO.AU\", \"SUL.AU\", \"SUN.AU\", \"SVW.AU\", \"SWM.AU\", \"SYD.AU\", \"SXL.AU\", \"TAH.AU\", \"TCL.AU\", \"TGR.AU\",\n",
    "    \"TLS.AU\", \"TLX.AU\", \"TNE.AU\", \"TPG.AU\", \"TWE.AU\", \"URW.AU\", \"VCX.AU\", \"VEA.AU\", \"VOC.AU\", \"VNT.AU\",\n",
    "    \"VUK.AU\", \"WBC.AU\", \"WEB.AU\", \"WES.AU\", \"WMC.AU\", \"WOR.AU\", \"WOW.AU\", \"WPL.AU\", \"WPR.AU\", \"WSA.AU\",\n",
    "    \"WTC.AU\", \"XRO.AU\", \"YAL.AU\", \"Z1P.AU\"\n",
    "]\n",
    "\n",
    "# Combine all tickers and sort\n",
    "all_tickers = sorted(au_share_tickers + us_share_tickers + forex_metals_tickers)\n",
    "\n",
    "# Create DataFrame and export to CSV\n",
    "df = pd.DataFrame(all_tickers, columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f9323fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Storing here again JIC\n",
    "# #! python3\n",
    "# # mouseNow.py - Displays the mouse cursor's current position.\n",
    "# import pyautogui\n",
    "# import time\n",
    "# #Mouse coordinates. = x = (0,1919) y = (0,1079)\n",
    "\n",
    "# pyautogui.PAUSE = 4\n",
    "\n",
    "# #Get to Pepperstone app\n",
    "# pyautogui.click(25, 900)\n",
    "# # pyautogui.PAUSE = 1\n",
    "# pyautogui.click(350, 200)\n",
    "# #pyautogui.hotkey('alt', 'tab')\n",
    "# pyautogui.PAUSE = 2\n",
    "\n",
    "# #Get to currency page\n",
    "# pyautogui.hotkey('ctrl', 'u')\n",
    "\n",
    "# #Get to Bars\n",
    "# pyautogui.click(500, 235)\n",
    "# #Download AUDUSD\n",
    "# pyautogui.typewrite(\"audusd\")\n",
    "# pyautogui.hotkey('enter')\n",
    "# pyautogui.hotkey('tab')\n",
    "# pyautogui.typewrite('d') #Daily\n",
    "# pyautogui.click(1000, 265) #Request\n",
    "# pyautogui.click(480, 640) #Export\n",
    "# #time.sleep(2)\n",
    "# pyautogui.click(700, 215) #Change the directory for these\n",
    "# pyautogui.typewrite(\"C:\\\\Users\\\\nitis\\\\Documents\\\\Forex\\\\Data\\\\New data\") #Use directory\n",
    "# pyautogui.hotkey('enter')\n",
    "# pyautogui.click(700, 550) #Change the name\n",
    "# pyautogui.typewrite('audusd') #Save file as aud\n",
    "# pyautogui.hotkey('enter')\n",
    "# pyautogui.typewrite('y')\n",
    "\n",
    "# #Loop through all currencies, len(daily)\n",
    "# for i in range(0,len(Curr)):\n",
    "#     pyautogui.click(490, 265) #Currency type\n",
    "#     pyautogui.typewrite(Curr[i])\n",
    "#     pyautogui.hotkey('enter')\n",
    "#     pyautogui.click(1000, 265) #Request\n",
    "#     pyautogui.click(480, 640) #Export\n",
    "# #    time.sleep(2)\n",
    "#     pyautogui.typewrite(Curr[i]) #Save file \n",
    "#     pyautogui.hotkey('enter')\n",
    "#     pyautogui.typewrite('y')\n",
    "\n",
    "# #Exit currency page\n",
    "# pyautogui.hotkey('esc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
